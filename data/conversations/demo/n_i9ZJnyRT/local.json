{"messages": [{"id": "user_90c12b43-d452-4dc9-be17-a7ca2ebb7c97", "role": "user", "content": "要約して", "createdAt": 1763528166355}, {"id": "assistant_c2135473-c409-44ee-a059-45290e82a29b", "role": "assistant", "content": "要約に失敗しました: map_llm_error: name 'RAGService' is not defined", "createdAt": 1763528166355}, {"id": "user_12713899-3db4-4adc-9cd8-62ac56077f75", "role": "user", "content": "ゼロショットプロンプトとは", "createdAt": 1763528230218}, {"id": "assistant_723f551c-8a40-4c02-b1ca-86a5ca6bf448", "role": "assistant", "content": "ゼロショットプロンプトは、モデルが以前に訓練された事例を見たことがないようなタスクに対して、直接的な指示を与えてモデルを推論させる方法です。この手法では、モデルは新規な未見の入力に対して即座に対応する能力が必要となります。\n\nノートブックのコンテキストでは、プロンプト内に例を提供することが非常に効果的であるというベストプラクティスが説明されています。しかし、ゼロショットプロンプトは具体的な例を提供しないで、直接的な指示を与える方法です。\n\nしたがって、ゼロショットプロンプトでは、モデルに特定のタスクを直截的に要求し、そのタスクに必要な情報を含む例や背景知識は与えません。これにより、モデルは新しい状況に対しても適切な応答を生成する能力を示すことが期待されます。", "citations": [{"id": "1", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 45, "snippet": "Prompt Engineering May 2025 ベストプラクティス 適切なプロンプトを見つけるには試行錯誤が必要です。Vertex AI の Language Studio は、様々なモデルに対して テストできる機能を備えており、プロンプトで色々と試すのに最適な場所です。 以下のベストプラクティスを活用し て、プロンプトエンジニアリングのプロになりましょう。 最も重要なベストプラクティスは、プロンプト内に（ワンショット/ フューショットの） 例 を提 供することです。…", "anchor_phrase": "Prompt Engineering\nMay 2025\nベストプラクティス\n適切なプロンプトを見つけるには試行錯誤が必要です。Vertex AI の Language Studio は、様々なモデルに対して\nテストできる機能を備えており、プロンプトで色々と試すのに最適な場所です。 以下のベストプラクティスを活用し\nて、プロンプトエンジニアリングのプロになりましょう。\n最も重要なベストプラクティスは、プロンプト内に（ワンショット/ フューショットの） 例 を提 供することです。これ\nは非常に効果的です。なぜなら、それが強力な指導ツールとして機能するからです。これらの例は、望ましい出力\nや類似の応答を示し、モデルがそれらから学習して自身の生成をそれに応じて調整することを可能にします。これ\nは、モデルに目指すべき参照点やターゲッ トを与えるようなものであり、応答の正確性、スタイル、 トーンを改善し、\n期待により良く合致させる効果があります。\nプロンプトは、人間にとってもモデルにとっても、簡潔、明確、そして理解しやすいものであるべきです。目安とし\nて、もし人間にとって既に紛らわしいものであれば、それはモデルにとっても同様に紛らわしい可能性が高いでしょ", "anchor_char_start": null, "anchor_char_end": null}, {"id": "2", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 25, "snippet": "れて いるノートブック 10 を参照してください。 本章の 「ベストプラクティス」 セクションでは、Chain of Thought プロンプティ ングに特化したベストプラクティスについて解説します。 大規模言語モデル（LLM）は様々な NLP タスクで目覚ましい成功を収めてきましたが、その推論能力は、単にモ デルサイズを大きくするだけでは克服できない限界だとしばしば見なされています。前の Chain of Thought プロン プティングのセクションで学んだように、人間が…", "anchor_phrase": "れて\nいるノートブック\n10\nを参照してください。 本章の 「ベストプラクティス」 セクションでは、Chain of Thought プロンプティ\nングに特化したベストプラクティスについて解説します。\n大規模言語モデル（LLM）は様々な NLP タスクで目覚ましい成功を収めてきましたが、その推論能力は、単にモ\nデルサイズを大きくするだけでは克服できない限界だとしばしば見なされています。前の Chain of Thought プロン\nプティングのセクションで学んだように、人間が問題を解くように、モデルに推論ステップを生成させることができ\nます。しかしながら、CoT は単純な「グリーディーデコーディング」戦略を用いるため、その有効性には限界があ\nります。自己整合性 (Self-consistency)¹¹ は、サンプリングと多数決を組み合わせることで、多様な推論パスを生\n成し、その中から最も一貫性のある回答を選択する手法です。これにより、LLM によって生成される応答の正確性\nと一貫性が向上します。\n自己整合性によって、 回答が正しいことの疑似確率的な確からしさが得られますが、 明らかにコストは高くなります。", "anchor_char_start": null, "anchor_char_end": null}, {"id": "3", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 49, "snippet": "バージョンを試し、新しいモデル機能をより良く活用できるようにプロンプトを調 整しましょう。Vertex AI Studio のようなツールは、プロンプトの様々なバージョンを保存、テスト、そして文書化 するのに非常に役立ちます。 分類タスクにおけるフューショット：クラスの混合 49", "anchor_phrase": "バージョンを試し、新しいモデル機能をより良く活用できるようにプロンプトを調\n整しましょう。Vertex AI Studio のようなツールは、プロンプトの様々なバージョンを保存、テスト、そして文書化\nするのに非常に役立ちます。\n分類タスクにおけるフューショット：クラスの混合\nモデル更新への適応\n49", "anchor_char_start": null, "anchor_char_end": null}, {"id": "4", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 24, "snippet": "of Thought プロンプティングの例 プロンプト プロンプト 1. 私の現在の年齢を「x」 歳 だと仮 定しましょう。 2. 私が 3 歳のとき、私の年齢は 3 歳でした。 3. その時のパートナー（相手）の年齢は私の年齢の 3 倍だったので、 パートナー（相手） の年齢は 3 * 3 = 9 歳でした。 4. 現在、私は 20 歳です。これは、私が 3 歳だった時から年齢が 20 - 3 = 17 年増えた ことを意味します。 5. 私が 3 歳のときパートナー（相手…", "anchor_phrase": "of Thought プロンプティングの例\nプロンプト\nプロンプト\n出力結果\n出力結果\n1. 私の現在の年齢を「x」 歳 だと仮 定しましょう。\n2. 私が 3 歳のとき、私の年齢は 3 歳でした。\n3. その時のパートナー（相手）の年齢は私の年齢の 3 倍だったので、 パートナー（相手）\nの年齢は 3 * 3 = 9 歳でした。\n4. 現在、私は 20 歳です。これは、私が  3 歳だった時から年齢が 20 - 3 = 17 年増えた\nことを意味します。\n5. 私が 3 歳のときパートナー（相手）は 9 歳 で あ り 、私 の 年 齢 が 17 年増えたので、 パー\nトナー（相手）の年齢も同様に  17 年増えているはずです。\n6. したがって、パートナー（相手）の現在の年齢は 9 + 17 = 26 歳です。\nよって、私のパートナー（相手）は 26 歳です。\n私が 3 歳 の とき、パ ートナ ー は 3 * 3 = 9 歳でした。これは  6 歳の年齢差で、 パートナー\nの方が年上です。現在私は  20 歳なので、パートナーは 20 + 6 = 26 歳です。答えは \n26 です。", "anchor_char_start": null, "anchor_char_end": null}], "segments": [{"text": "ゼロショットプロンプトは、モデルが以前に訓練された事例を見たことがないようなタスクに対して、直接的な指示を与えてモデルを推論させる方法です。", "citationIndices": [0, 1]}, {"text": "この手法では、モデルは新規な未見の入力に対して即座に対応する能力が必要となります。", "citationIndices": [2, 3]}, {"text": "ノートブックのコンテキストでは、プロンプト内に例を提供することが非常に効果的であるというベストプラクティスが説明されています。", "citationIndices": [0, 1]}, {"text": "しかし、ゼロショットプロンプトは具体的な例を提供しないで、直接的な指示を与える方法です。", "citationIndices": [2, 3]}, {"text": "したがって、ゼロショットプロンプトでは、モデルに特定のタスクを直截的に要求し、そのタスクに必要な情報を含む例や背景知識は与えません。", "citationIndices": [0, 1]}, {"text": "これにより、モデルは新しい状況に対しても適切な応答を生成する能力を示すことが期待されます。", "citationIndices": [2, 3]}], "createdAt": 1763528230218}, {"id": "user_fa7037b4-905e-44bd-8f1c-465afbf17ec4", "role": "user", "content": "ゼロショットプロンプトとは", "createdAt": 1763535953412}, {"id": "assistant_f9696b44-b937-49ec-89e9-c52a153ac1a6", "role": "assistant", "content": "ゼロショットプロンプトは、モデルに以前学習した事例やデータが存在しない新しいタスクに対して適切な応答を生成するための手法です。この手法では、モデルは与えられたプロンプトから推論し、類似性や関連性に基づいて解答を作成します。\n\nノートブックのコンテキストでは、プロンプト内に例を提供することが非常に効果的であると強調されています。これは、モデルが望ましい出力や類似の応答を生成するための参考点やターゲットを与え、応答の正確性、スタイル、トーンを改善し、期待により良く合致させるのに役立ちます。\n\nしかし、ゼロショットプロンプトでは既存の事例が提供されていないため、モデルは独自に推論を行う必要があります。そのため、適切なプロンプト作成は重要な要素となります。", "citations": [{"id": "1", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 45, "snippet": "Prompt Engineering May 2025 ベストプラクティス 適切なプロンプトを見つけるには試行錯誤が必要です。Vertex AI の Language Studio は、様々なモデルに対して テストできる機能を備えており、プロンプトで色々と試すのに最適な場所です。 以下のベストプラクティスを活用し て、プロンプトエンジニアリングのプロになりましょう。 最も重要なベストプラクティスは、プロンプト内に（ワンショット/ フューショットの） 例 を提 供することです。…", "anchor_phrase": "Prompt Engineering\nMay 2025\nベストプラクティス\n適切なプロンプトを見つけるには試行錯誤が必要です。Vertex AI の Language Studio は、様々なモデルに対して\nテストできる機能を備えており、プロンプトで色々と試すのに最適な場所です。 以下のベストプラクティスを活用し\nて、プロンプトエンジニアリングのプロになりましょう。\n最も重要なベストプラクティスは、プロンプト内に（ワンショット/ フューショットの） 例 を提 供することです。これ\nは非常に効果的です。なぜなら、それが強力な指導ツールとして機能するからです。これらの例は、望ましい出力\nや類似の応答を示し、モデルがそれらから学習して自身の生成をそれに応じて調整することを可能にします。これ\nは、モデルに目指すべき参照点やターゲッ トを与えるようなものであり、応答の正確性、スタイル、 トーンを改善し、\n期待により良く合致させる効果があります。\nプロンプトは、人間にとってもモデルにとっても、簡潔、明確、そして理解しやすいものであるべきです。目安とし\nて、もし人間にとって既に紛らわしいものであれば、それはモデルにとっても同様に紛らわしい可能性が高いでしょ", "anchor_char_start": null, "anchor_char_end": null}, {"id": "2", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 25, "snippet": "れて いるノートブック 10 を参照してください。 本章の 「ベストプラクティス」 セクションでは、Chain of Thought プロンプティ ングに特化したベストプラクティスについて解説します。 大規模言語モデル（LLM）は様々な NLP タスクで目覚ましい成功を収めてきましたが、その推論能力は、単にモ デルサイズを大きくするだけでは克服できない限界だとしばしば見なされています。前の Chain of Thought プロン プティングのセクションで学んだように、人間が…", "anchor_phrase": "れて\nいるノートブック\n10\nを参照してください。 本章の 「ベストプラクティス」 セクションでは、Chain of Thought プロンプティ\nングに特化したベストプラクティスについて解説します。\n大規模言語モデル（LLM）は様々な NLP タスクで目覚ましい成功を収めてきましたが、その推論能力は、単にモ\nデルサイズを大きくするだけでは克服できない限界だとしばしば見なされています。前の Chain of Thought プロン\nプティングのセクションで学んだように、人間が問題を解くように、モデルに推論ステップを生成させることができ\nます。しかしながら、CoT は単純な「グリーディーデコーディング」戦略を用いるため、その有効性には限界があ\nります。自己整合性 (Self-consistency)¹¹ は、サンプリングと多数決を組み合わせることで、多様な推論パスを生\n成し、その中から最も一貫性のある回答を選択する手法です。これにより、LLM によって生成される応答の正確性\nと一貫性が向上します。\n自己整合性によって、 回答が正しいことの疑似確率的な確からしさが得られますが、 明らかにコストは高くなります。", "anchor_char_start": null, "anchor_char_end": null}, {"id": "3", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 49, "snippet": "バージョンを試し、新しいモデル機能をより良く活用できるようにプロンプトを調 整しましょう。Vertex AI Studio のようなツールは、プロンプトの様々なバージョンを保存、テスト、そして文書化 するのに非常に役立ちます。 分類タスクにおけるフューショット：クラスの混合 49", "anchor_phrase": "バージョンを試し、新しいモデル機能をより良く活用できるようにプロンプトを調\n整しましょう。Vertex AI Studio のようなツールは、プロンプトの様々なバージョンを保存、テスト、そして文書化\nするのに非常に役立ちます。\n分類タスクにおけるフューショット：クラスの混合\nモデル更新への適応\n49", "anchor_char_start": null, "anchor_char_end": null}, {"id": "4", "doc_id": "demo:n_i9ZJnyRT:01_prompt_engineering_jpn.pdf", "title": "01_prompt_engineering_jpn.pdf", "uri": "data/source/__library_tmp__/041bae4d06714fc592f89aa072c776e9/01_prompt_engineering_jpn.pdf", "page": 24, "snippet": "of Thought プロンプティングの例 プロンプト プロンプト 1. 私の現在の年齢を「x」 歳 だと仮 定しましょう。 2. 私が 3 歳のとき、私の年齢は 3 歳でした。 3. その時のパートナー（相手）の年齢は私の年齢の 3 倍だったので、 パートナー（相手） の年齢は 3 * 3 = 9 歳でした。 4. 現在、私は 20 歳です。これは、私が 3 歳だった時から年齢が 20 - 3 = 17 年増えた ことを意味します。 5. 私が 3 歳のときパートナー（相手…", "anchor_phrase": "of Thought プロンプティングの例\nプロンプト\nプロンプト\n出力結果\n出力結果\n1. 私の現在の年齢を「x」 歳 だと仮 定しましょう。\n2. 私が 3 歳のとき、私の年齢は 3 歳でした。\n3. その時のパートナー（相手）の年齢は私の年齢の 3 倍だったので、 パートナー（相手）\nの年齢は 3 * 3 = 9 歳でした。\n4. 現在、私は 20 歳です。これは、私が  3 歳だった時から年齢が 20 - 3 = 17 年増えた\nことを意味します。\n5. 私が 3 歳のときパートナー（相手）は 9 歳 で あ り 、私 の 年 齢 が 17 年増えたので、 パー\nトナー（相手）の年齢も同様に  17 年増えているはずです。\n6. したがって、パートナー（相手）の現在の年齢は 9 + 17 = 26 歳です。\nよって、私のパートナー（相手）は 26 歳です。\n私が 3 歳 の とき、パ ートナ ー は 3 * 3 = 9 歳でした。これは  6 歳の年齢差で、 パートナー\nの方が年上です。現在私は  20 歳なので、パートナーは 20 + 6 = 26 歳です。答えは \n26 です。", "anchor_char_start": null, "anchor_char_end": null}], "segments": [{"text": "ゼロショットプロンプトは、モデルに以前学習した事例やデータが存在しない新しいタスクに対して適切な応答を生成するための手法です。", "citationIndices": [0, 1]}, {"text": "この手法では、モデルは与えられたプロンプトから推論し、類似性や関連性に基づいて解答を作成します。", "citationIndices": [2, 3]}, {"text": "ノートブックのコンテキストでは、プロンプト内に例を提供することが非常に効果的であると強調されています。", "citationIndices": [0]}, {"text": "これは、モデルが望ましい出力や類似の応答を生成するための参考点やターゲットを与え、応答の正確性、スタイル、トーンを改善し、期待により良く合致させるのに役立ちます。", "citationIndices": [1, 2]}, {"text": "しかし、ゼロショットプロンプトでは既存の事例が提供されていないため、モデルは独自に推論を行う必要があります。", "citationIndices": [3, 0]}, {"text": "そのため、適切なプロンプト作成は重要な要素となります。", "citationIndices": [0, 2]}], "createdAt": 1763535953412}], "updated_at": 1763536003.899022}